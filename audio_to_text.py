# ===================================================
# LEGACY BACKUP FILE - NOT USED IN CURRENT SYSTEM
# ===================================================
# This file uses Whisper API for speech-to-text conversion.
# The current system now uses direct audio processing 
# with gpt-4o-mini-audio-preview-2024-12-17 model
# in LLM_conversation.py and LLM_function.py
# ===================================================

import os
import io
import time
import numpy as np
import sounddevice as sd
import soundfile as sf
import keyboard           # pip install keyboard
import openai
from dotenv import load_dotenv  # pip install python-dotenv
from function import process_voice_text  # ê¸°ëŠ¥ êµ¬í˜„.pyì—ì„œ í•¨ìˆ˜ ì„í¬íŠ¸

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 1) í™˜ê²½ ë³€ìˆ˜ì— OpenAI API í‚¤ ì„¤ì •
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
openai.api_key = os.getenv("OPENAI_API_KEY")

if not openai.api_key:
    raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ê±°ë‚˜ ì§ì ‘ í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = openai.OpenAI()

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 2) ë…¹ìŒ/ë³€í™˜ ì„¤ì •
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
SAMPLE_RATE = 16000    # Whisper ê¶Œì¥ ìƒ˜í”Œë§ ë ˆì´íŠ¸
CHANNELS = 1           # ëª¨ë…¸
KEY = "space"          # ë…¹ìŒ ì œì–´ í‚¤

frames = []
recording = False

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 3) ìŠ¤íŠ¸ë¦¼ ì½œë°±: recordingì´ Trueì¼ ë•Œë§Œ ë°ì´í„° ìˆ˜ì§‘
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def audio_callback(indata, frames_count, time_info, status):
    global frames
    if status:
        print(f"âš ï¸ ë…¹ìŒ ê²½ê³ : {status}")
    if recording:
        frames.append(indata.copy())

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 4) ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì—´ê¸°
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
stream = sd.InputStream(
    samplerate=SAMPLE_RATE,
    channels=CHANNELS,
    callback=audio_callback
)
stream.start()
print("ğŸš€ ìŠ¤íŠ¸ë¦¼ ì—´ë¦¼. ìŠ¤í˜ì´ìŠ¤ë°”ë¥¼ ëˆŒëŸ¬ ë…¹ìŒì„ ì‹œì‘í•˜ì„¸ìš”.")

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# 5) ë©”ì¸ ë£¨í”„: í‚¤ ì…ë ¥ ê°ì§€ â†’ ë…¹ìŒ â†’ Whisper ì „ì†¡
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
try:
    while True:
        # ìŠ¤í˜ì´ìŠ¤ë°” ëˆ„ë¥´ë©´ ë…¹ìŒ ì‹œì‘
        if keyboard.is_pressed(KEY) and not recording:
            recording = True
            frames.clear()
            print("âºï¸ ë…¹ìŒ ì‹œì‘â€¦ (í‚¤ì—ì„œ ì† ë–¼ë©´ ì „ì†¡)")

        # í‚¤ì—ì„œ ì† ë–¼ë©´ ë…¹ìŒ ì¢…ë£Œ & Whisper API í˜¸ì¶œ
        if recording and not keyboard.is_pressed(KEY):
            recording = False
            print("â¹ï¸ ë…¹ìŒ ì¢…ë£Œ. Whisperì— ì „ì†¡ ì¤‘â€¦")

            # (1) numpy ë°°ì—´ë¡œ í•©ì¹˜ê¸°
            audio_data = np.concatenate(frames, axis=0)

            # (2) BytesIOì— WAVë¡œ ì €ì¥
            wav_buffer = io.BytesIO()
            sf.write(wav_buffer, audio_data, SAMPLE_RATE,
                     format="WAV", subtype="PCM_16")
            
            # íŒŒì¼ ì´ë¦„ ì§€ì • (í™•ì¥ì ì¸ì‹ì„ ìœ„í•´ í•„ìš”)
            wav_buffer.name = "audio.wav"
            
            wav_buffer.seek(0)

            # (3) Whisper API í˜¸ì¶œ
            try:
                resp = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=wav_buffer,
                    response_format="text",
                    language="en"
                )
                converted_text = resp.strip()
                print(f"[{time.strftime('%H:%M:%S')}] ë³€í™˜ ê²°ê³¼:")
                print(converted_text)

                # í…ìŠ¤íŠ¸ ë³€í™˜ ì„±ê³µ ì‹œ GPT ì²˜ë¦¬ ì‹¤í–‰
                if converted_text:
                    print("\nğŸ”„ GPTë¡œ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì¤‘...")
                    process_voice_text(converted_text)

            except Exception as e:
                print("âŒ ë³€í™˜ ì˜¤ë¥˜:", e)

            print("\nğŸ”„ ë‹¤ìŒ ë…¹ìŒì„ ìœ„í•´ ìŠ¤í˜ì´ìŠ¤ë°”ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”.\n")

        time.sleep(0.05)

except KeyboardInterrupt:
    print("\nğŸ”Œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    stream.stop()
    stream.close()

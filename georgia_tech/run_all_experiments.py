#!/usr/bin/env python3
"""
DrafterBench ìë™ ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸
ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ ëª¨ë“  ëª¨ë¸ì„ ì‹¤í—˜í•˜ê³  ê²°ê³¼ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

import subprocess
import os
import time
import json
from datetime import datetime

# ì‹¤í—˜í•  ëª¨ë¸ë“¤ (ìš°ì„ ìˆœìœ„ ìˆœì„œ)
MODELS = [
    # 1ë‹¨ê³„: DeepSeek ëª¨ë¸ë“¤
    {
        "name": "DeepSeek V3 0324",
        "model_id": "deepseek-ai/DeepSeek-V3-0324",
        "exp_name": "deepseek_v3_drafterbench"
    },
    {
        "name": "DeepSeek R1 0528", 
        "model_id": "deepseek-ai/DeepSeek-R1-0528",
        "exp_name": "deepseek_r1_drafterbench"
    },
    # 2ë‹¨ê³„: Qwen 235B ì‹œë¦¬ì¦ˆ
    {
        "name": "Qwen 3 235B",
        "model_id": "togetherai/Qwen/Qwen3-235B-A22B-FP8",
        "exp_name": "qwen_235b_drafterbench"
    },
    {
        "name": "Qwen 3 235B Instruct",
        "model_id": "togetherai/Qwen/Qwen3-235B-A22B-Instruct-2507-FP8", 
        "exp_name": "qwen_235b_instruct_drafterbench"
    },
    {
        "name": "Qwen 3 235B Thinking",
        "model_id": "togetherai/Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
        "exp_name": "qwen_235b_thinking_drafterbench"
    },
    # 3ë‹¨ê³„: Gemini 2.5 ì‹œë¦¬ì¦ˆ
    {
        "name": "Gemini 2.5 Pro", 
        "model_id": "google/gemini-2.5-pro-thinking-off",
        "exp_name": "gemini_2_5_pro_drafterbench"
    },
    {
        "name": "Gemini 2.5 Flash",
        "model_id": "google/gemini-2.5-flash-thinking-off",
        "exp_name": "gemini_2_5_flash_drafterbench"
    },
    # 4ë‹¨ê³„: ê¸°íƒ€ ëª¨ë¸ë“¤
    {
        "name": "Grok 4",
        "model_id": "xai/grok-4", 
        "exp_name": "grok_4_drafterbench"
    },
    {
        "name": "K2 Instruct",
        "model_id": "togetherai/moonshotai/Kimi-K2-Instruct",
        "exp_name": "k2_instruct_drafterbench"
    }
]

def setup_environment():
    """í™˜ê²½ë³€ìˆ˜ ì„¤ì •"""
    os.environ["OPENAI_API_KEY"] = "sk-sgl-MH7bEVVJlBp3RT_P5cPQ6-KfC1qJElBRCfTDHy40Ue4"
    os.environ["ANTHROPIC_API_KEY"] = "sk-sgl-MH7bEVVJlBp3RT_P5cPQ6-KfC1qJElBRCfTDHy40Ue4"
    os.environ["OPENAI_API_BASE"] = "http://5.78.122.79:10000/v1"
    print("âœ… í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ")

def run_experiment(model_info):
    """ë‹¨ì¼ ëª¨ë¸ ì‹¤í—˜ ì‹¤í–‰"""
    print(f"\nğŸš€ ì‹¤í—˜ ì‹œì‘: {model_info['name']}")
    print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    cmd = [
        "python", "evaluation.py",
        "--model", model_info["model_id"],
        "--model-provider", "custom_openai", 
        "--temperature", "0.0",
        "--exp_name", model_info["exp_name"],
        "--task_group", "All"
    ]
    
    start_time = time.time()
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=7200)  # 2ì‹œê°„ íƒ€ì„ì•„ì›ƒ
        
        end_time = time.time()
        duration = end_time - start_time
        
        if result.returncode == 0:
            print(f"âœ… ì‹¤í—˜ ì™„ë£Œ: {model_info['name']}")
            print(f"â±ï¸  ì†Œìš” ì‹œê°„: {duration/60:.1f}ë¶„")
            return True, result.stdout, duration
        else:
            print(f"âŒ ì‹¤í—˜ ì‹¤íŒ¨: {model_info['name']}")
            print(f"ì˜¤ë¥˜: {result.stderr}")
            return False, result.stderr, duration
            
    except subprocess.TimeoutExpired:
        print(f"â° ì‹¤í—˜ íƒ€ì„ì•„ì›ƒ: {model_info['name']} (2ì‹œê°„ ì´ˆê³¼)")
        return False, "Timeout after 2 hours", 7200
    except Exception as e:
        print(f"ğŸ’¥ ì˜ˆì™¸ ë°œìƒ: {model_info['name']} - {str(e)}")
        return False, str(e), 0

def extract_results():
    """ê²°ê³¼ ì¶”ì¶œ"""
    print("\nğŸ“Š ê²°ê³¼ ì¶”ì¶œ ì¤‘...")
    results_dir = "results"
    
    if not os.path.exists(results_dir):
        print("âŒ results ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {}
    
    results = {}
    for model_dir in os.listdir(results_dir):
        model_path = os.path.join(results_dir, model_dir)
        if os.path.isdir(model_path):
            # ê°€ì¥ ìµœê·¼ ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
            txt_files = [f for f in os.listdir(model_path) if f.endswith('.txt')]
            if txt_files:
                latest_file = max(txt_files)
                result_file = os.path.join(model_path, latest_file)
                try:
                    with open(result_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        results[model_dir] = content
                except Exception as e:
                    print(f"ê²°ê³¼ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {result_file} - {str(e)}")
    
    return results

def save_experiment_log(model_info, success, output, duration):
    """ì‹¤í—˜ ë¡œê·¸ ì €ì¥"""
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "model_name": model_info["name"],
        "model_id": model_info["model_id"], 
        "exp_name": model_info["exp_name"],
        "success": success,
        "duration_seconds": duration,
        "output": output[:1000] if output else ""  # ì²˜ìŒ 1000ìë§Œ ì €ì¥
    }
    
    log_file = "experiment_log.json"
    if os.path.exists(log_file):
        with open(log_file, 'r') as f:
            logs = json.load(f)
    else:
        logs = []
    
    logs.append(log_entry)
    
    with open(log_file, 'w') as f:
        json.dump(logs, f, indent=2, ensure_ascii=False)

def main():
    """ë©”ì¸ ì‹¤í—˜ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¯ DrafterBench ìë™ ì‹¤í—˜ ì‹œì‘!")
    print(f"ğŸ“‹ ì´ {len(MODELS)}ê°œ ëª¨ë¸ ì‹¤í—˜ ì˜ˆì •")
    
    setup_environment()
    
    start_time = time.time()
    successful_experiments = 0
    
    for i, model_info in enumerate(MODELS, 1):
        print(f"\n{'='*50}")
        print(f"ğŸ“ˆ ì§„í–‰ë¥ : {i}/{len(MODELS)}")
        
        success, output, duration = run_experiment(model_info)
        save_experiment_log(model_info, success, output, duration)
        
        if success:
            successful_experiments += 1
        
        # ì§§ì€ íœ´ì‹ (API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ë°©ì§€)
        if i < len(MODELS):
            print("ğŸ˜´ 10ì´ˆ ëŒ€ê¸° ì¤‘...")
            time.sleep(10)
    
    # ìµœì¢… ê²°ê³¼ ì •ë¦¬
    total_time = time.time() - start_time
    print(f"\n{'='*60}")
    print("ğŸ ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ!")
    print(f"âœ… ì„±ê³µí•œ ì‹¤í—˜: {successful_experiments}/{len(MODELS)}")
    print(f"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {total_time/3600:.1f}ì‹œê°„")
    
    # ê²°ê³¼ ì¶”ì¶œ
    results = extract_results()
    print(f"ğŸ“Š ì¶”ì¶œëœ ê²°ê³¼: {len(results)}ê°œ")
    
    return results

if __name__ == "__main__":
    main()

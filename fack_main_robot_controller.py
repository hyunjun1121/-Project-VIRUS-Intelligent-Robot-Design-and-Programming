from multiprocessing import process
import os
import io
import queue
import time
import json
from typing import Any
import numpy as np
import sounddevice as sd
import soundfile as sf
from dotenv import load_dotenv
import openai
import threading
#import pygame
# Import the modules needed for the complete system
from LLM_function import process_voice_text as process_for_commands, process_voice_audio as process_for_audio_commands
from LLM_conversation import process_voice_text as process_for_conversation, process_voice_audio as process_for_audio_conversation
from text_to_audio import text_to_speech
from client_vlm_parallel_alt import main as run_vlm_alt
import json

from bt import BT
from client_face_parallel import main as run_face_alt
class MultiThreadManagerfaces:
	def __init__(self):
		self.face_thread = None
		self.face_result = None
		self.face_complete = threading.Event()
		self.face_lock = threading.Lock()

	def start_face_processing(self):
		"""
		face_area ëª¨ë“œë¡œ run_face_altë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰.
		ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ì¬ì‹¤í–‰í•˜ì§€ ì•ŠìŒ.
		"""
		with self.face_lock:
			if self.face_thread is None or not self.face_thread.is_alive():
				self.face_complete.clear()
				self.face_thread = threading.Thread(
					target=self._run_face,
					daemon=True
				)
				self.face_thread.start()
			else:
				print("[face] Processing already running")

	def _run_face(self):
		"""
		ì‹¤ì œë¡œ face ì²˜ë¦¬ í•¨ìˆ˜(run_face_alt)ë¥¼ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ self.face_resultì— ì €ì¥.
		ì™„ë£Œ í”Œë˜ê·¸(face_complete)ë¥¼ ë§ˆì§€ë§‰ì— ì„¸íŒ….
		"""
		try:
			# lockì„ ì‚¬ìš©í•´ ë™ì‹œ ì ‘ê·¼ ë°©ì§€
			with self.face_lock:
				self.face_result = run_face_alt(mode="image")
		except Exception as e:
			print(f"[face] Error during processing: {e}")
			with self.face_lock:
				self.face_result = None
		finally:
			# face ì²˜ë¦¬ ì™„ë£Œ ì‹ í˜¸
			self.face_complete.set()

	def get_face_result(self, timeout=30):
		"""
		face ì²˜ë¦¬ê°€ ëë‚  ë•Œê¹Œì§€ ìµœëŒ€ timeout ì´ˆ ëŒ€ê¸°. 
		ì™„ë£Œë˜ë©´ JSON ë¬¸ìì—´(self.face_result)ì„ ë°˜í™˜, 
		íƒ€ì„ì•„ì›ƒì´ ë‚˜ë©´ Noneì„ ë°˜í™˜.
		"""
		finished = self.face_complete.wait(timeout)
		with self.face_lock:
			return self.face_result if finished else None

# -----------------------------------------------------
# HubController: Bluetooth ì—°ê²° ë° ëª…ë ¹ ì „ì†¡ ê´€ë¦¬
# -----------------------------------------------------
class HubController:
	def __init__(self, hub_id, address):
		self.hub_id = hub_id
		self.address = address
		self.sock = None
		self.lock = threading.Lock()
		self.bt = BT()
		self._connect()

	def _connect(self):
		"""
		BT.connect(address)ë¥¼ í˜¸ì¶œí•˜ì—¬ self.sockì— ì†Œì¼“ í• ë‹¹.
		ì‹¤íŒ¨ ì‹œ self.sockì€ Noneìœ¼ë¡œ ë‚¨ìŒ.
		"""
		print(f"[{self.hub_id}] ì—°ê²° ì‹œë„...")
		try:
			self.sock = self.bt.connect(self.address)
			print(f"[{self.hub_id}] ì—°ê²° ì„±ê³µ!")
		except Exception as e:
			print(f"[{self.hub_id}] ì—°ê²° ì‹¤íŒ¨: {e}")
			self.sock = None

	def send_single_command(self, cmd_json_str):
		"""
		ë‹¨ì¼ ëª…ë ¹(cmd_json_str: JSON ë¬¸ìì—´)ì„ Bluetooth ì†Œì¼“ìœ¼ë¡œ ì „ì†¡í•˜ê³ ,
		'<<<<<<suc>>>>>>' ì‘ë‹µì´ ì˜¬ ë•Œê¹Œì§€ ëŒ€ê¸°.
		"""
		if not cmd_json_str:
			# ë¹ˆ ë¬¸ìì—´, None ë“± ë„˜ì–´ì˜¤ë©´ ì•„ë¬´ê²ƒë„ ì•ˆ í•˜ê³  True ë°˜í™˜
			return True

		with self.lock:
			try:
				# JSON ë¬¸ìì—´ ë’¤ì— '\n' ë¶™ì—¬ ì „ì†¡ 
				self.sock.send((cmd_json_str + "\n").encode("utf-8"))

				# ì‘ë‹µ ë²„í¼ì— '<<<<<<suc>>>>>>' í† í°ì´ ë‚˜ì˜¬ ë•Œê¹Œì§€ ëŒ€ê¸°
				buf = b""
				while b"<<<<<<suc>>>>>>" not in buf:
					chunk = self.sock.recv(4096)
					if not chunk:
						# ì—°ê²°ì´ ëŠê¸°ë©´ break
						break
					buf += chunk

				print(f"[{self.hub_id}] ì‹¤í–‰ ì™„ë£Œ: {cmd_json_str}")
				return True

			except Exception as e:
				print(f"[{self.hub_id}] ì˜¤ë¥˜ ë°œìƒ: {e}")
				return False

# -----------------------------------------------------
# ìƒ˜í”Œ ëª…ë ¹(JSON ë¬¸ìì—´) (í•˜ë“œì½”ë”©ëœ ì˜ˆì‹œ)
# -----------------------------------------------------
SAMPLE_COMMANDS = {
	"hub1": '[ [ { "cmd": "move",     "val": 30 },  { "cmd": "rotate_x", "val": 20 } ] ]',
	"hub2": '[ [ { "cmd": "shoot",    "val":  1 },  { "cmd": "rotate_y", "val": 20 } ] ]'
}
# try:
#     from pi_exercise import main as run_spike
#     SPIKE_AVAILABLE = True
#     print("âœ… SPIKE robot control available")
# except ImportError as e:
#     print(f"âš ï¸ SPIKE robot control unavailable: {e}")
#     SPIKE_AVAILABLE = False
#     def run_spike(command):
#         print(f"ğŸ¤– [SIMULATION] Would execute robot command: {command}")

# Load environment variables for API keys
load_dotenv()
api_lock = threading.Lock()
sound_lock = threading.Lock()

# ì‚¬ìš©ì ì •ì˜ ì‘ë‹µ ì‚¬ì „ ì„¤ì •
PREDEFINED_RESPONSES = {
	# LLM_function.py ì‘ë‹µ (ë¡œë´‡ ëª…ë ¹)
	"commands": {
		"default": """[
[{"cmd": "move", "val": 100}]
]""",
		"hello": """[
[{"cmd": "steer", "val": 90}],
[{"cmd": "move", "val": 50}]
]""",
		"attack": """[
[{"cmd": "rotate_x", "val": 45}],
[{"cmd": "shoot", "val": 0}]
]""",
		"retreat": """[
[{"cmd": "move", "val": -100}]
]"""
	},
	
	# LLM_conversation.py ì‘ë‹µ (ëŒ€í™”)
	"conversation": {
		"default": "Affirmative. I am VIRUS, ready for your command.",
		"hello": "Hello operator. VIRUS combat unit online and ready for deployment.",
		"attack": "Target acquired. Engaging hostile elements.",
		"retreat": "Tactical withdrawal initiated. Moving to safe position."
	},
	
	# VLM ì‘ë‹µ (ì´ë¯¸ì§€ ë¶„ì„)
	"vlm": {
		"default": "The environment appears to be a standard indoor area with no immediate threats or obstacles.",
		"person": "I detect one human figure standing approximately 3 meters ahead. No visible weapons or hostile intent.",
		"empty": "The area is clear of any human presence or significant objects.",
		"obstacle": "There appears to be furniture and various obstacles in the path ahead. Recommend cautious navigation."
	}
}

# í˜„ì¬ ì„ íƒëœ ì‘ë‹µ (í‚¤ ì €ì¥)
CURRENT_SELECTIONS = {
	"commands": "default",
	"conversation": "default",
	"vlm": "default"
}
hub1 = HubController("hub1", "E0:FF:F1:59:8E:6A")
hub2 = HubController("hub2", "E0:FF:F1:58:52:A2")

# 2) face ì²˜ë¦¬ ë§¤ë‹ˆì € ìƒì„±
face_mgr = MultiThreadManagerfaces()
def fake_convert_audio_to_text_via_api(audio_data, sample_rate):
	"""ì‹¤ì œ Whisper API ëŒ€ì‹  ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
	print("\nğŸ­ [FAKE] ì‹¤ì œ ìŒì„± ë³€í™˜ ëŒ€ì‹  ì‚¬ìš©ì ì…ë ¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
	
	# ì‚¬ìš©ì ì…ë ¥ ìš”ì²­
	print("\nğŸ”¤ í…ìŠ¤íŠ¸ ì…ë ¥ (ê°€ìƒ ìŒì„± ëª…ë ¹):")
	user_input = input("> ")
	
	# íŠ¹ìˆ˜ ëª…ë ¹ì–´ ì²˜ë¦¬ (ì„ íƒ ë³€ê²½)
	if user_input.startswith("/set"):
		try:
			_, category, selection = user_input.split(" ", 2)
			if category in CURRENT_SELECTIONS and selection in PREDEFINED_RESPONSES[category]:
				CURRENT_SELECTIONS[category] = selection
				print(f"âœ… {category} ì‘ë‹µì´ '{selection}'ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
			else:
				print(f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ ë˜ëŠ” ì„ íƒ: {category} - {selection}")
				print(f"ìœ íš¨í•œ ì˜µì…˜: {list(PREDEFINED_RESPONSES.keys())} - {PREDEFINED_RESPONSES[category].keys() if category in PREDEFINED_RESPONSES else 'ì—†ìŒ'}")
		except ValueError:
			print("âŒ ëª…ë ¹ í˜•ì‹ ì˜¤ë¥˜. ì˜ˆ: /set commands attack")
			print("ê°€ëŠ¥í•œ ëª…ë ¹:")
			for category, options in PREDEFINED_RESPONSES.items():
				print(f"  /set {category} [{' | '.join(options.keys())}]")
		return user_input
	
	# ì‚¬ìš©ìê°€ ì•„ë¬´ê²ƒë„ ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ default ì‘ë‹µ ì‚¬ìš©ì„ ì•ˆë‚´
	if user_input.strip() == "":
		print("âœ… ë¹ˆ ì…ë ¥ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ê¸°ë³¸(default) ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
	
	return user_input

class MultiThreadManager:
	def __init__(self):
		self.vlm_thread = None
		self.vlm_result = None
		self.vlm_complete = threading.Event()
		
		self.conversation_thread = None
		self.conversation_result = None
		self.conversation_complete = threading.Event()
		
		self.lock = threading.Lock()
		
	def start_vlm_processing(self):
		with self.lock:
			if self.vlm_thread is None or not self.vlm_thread.is_alive():
				self.vlm_complete.clear()
				self.vlm_thread = threading.Thread(
					target=self._run_vlm,
					daemon=True
				)
				self.vlm_thread.start()
			else:
				print("[VLM] Processing already running")
				
	def _run_vlm(self):
		try:
			# ì‹¤ì œ VLM ëŒ€ì‹  ë¯¸ë¦¬ ì •ì˜ëœ ì‘ë‹µ ì‚¬ìš©
			print("\nğŸ­ [FAKE] ì‹¤ì œ VLM ë¶„ì„ ëŒ€ì‹  ë¯¸ë¦¬ ì •ì˜ëœ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
			selected_vlm = CURRENT_SELECTIONS["vlm"]
			result = PREDEFINED_RESPONSES["vlm"][selected_vlm]
			time.sleep(1)  # ì ì‹œ ì§€ì—°í•˜ì—¬ ì²˜ë¦¬ ì¤‘ì¸ ê²ƒì²˜ëŸ¼ ë³´ì´ê²Œ í•¨
			
			with self.lock:
				self.vlm_result = result
		except Exception as e:
			print(f"VLM error: {e}")
			with self.lock:
				self.vlm_result = None
		finally:
			self.vlm_complete.set()
			
	def get_vlm_result(self, timeout=30):
		finished = self.vlm_complete.wait(timeout)
		with self.lock:
			return self.vlm_result if finished else None
			
	def start_text_conversation_processing(self, transcribed_text, vlm_result):
		with self.lock:
			if self.conversation_thread is None or not self.conversation_thread.is_alive():
				self.conversation_complete.clear()
				self.conversation_thread = threading.Thread(
					target=self._run_text_conversation,
					args = [transcribed_text, vlm_result],
					daemon=True
				)
				self.conversation_thread.start()
			else:
				print("[Conversation] Processing already running")
				
	def _run_text_conversation(self, transcribed_text, vlm_result):
		result = False
		try:
			# ì‹¤ì œ LLM í˜¸ì¶œ ëŒ€ì‹  ë¯¸ë¦¬ ì •ì˜ëœ ì‘ë‹µ ì‚¬ìš©
			print("\nğŸ­ [FAKE] ì‹¤ì œ LLM ëŒ€ì‹  ë¯¸ë¦¬ ì •ì˜ëœ ëŒ€í™” ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
			selected_conversation = CURRENT_SELECTIONS["conversation"]
			conversation_response_text = PREDEFINED_RESPONSES["conversation"][selected_conversation]
			
			if conversation_response_text:
				print("\nğŸ”Š Converting response to speech...")
				response_file_path = text_to_speech(
					text=conversation_response_text,
					voice_id=VOICE_ID,
					output_filename=RESPONSE_AUDIO_FILE
				)
				result = True
				
				if response_file_path and os.path.exists(response_file_path):
					print(f"Conversational audio response saved to {RESPONSE_AUDIO_FILE}")
					# Try to play the audio response
					try:
						import pygame
						pygame.mixer.init()
						pygame.mixer.music.load(response_file_path)
						pygame.mixer.music.play()
						print("ğŸ”Š Playing response audio...")
						while pygame.mixer.music.get_busy():
							pygame.time.Clock().tick(10)
					except ImportError:
						print(f"Audio saved to {RESPONSE_AUDIO_FILE}. Install pygame to enable autoplay.")
					except Exception as e:
						print(f"Error playing audio: {e}")
			else:
				print("âš ï¸ No conversational response generated.")
				
			with self.lock:
				self.conversation_result = result
		except Exception as e:
			print(f"Conversation (text input) error: {e}")
			with self.lock:
				self.conversation_result = False
		finally:
			self.conversation_complete.set()
			
	def get_conversation_result(self, timeout=30):
		finished = self.conversation_complete.wait(timeout)
		with self.lock:
			return self.conversation_result if finished else None

# ê°€ì§œ process_for_commands í•¨ìˆ˜ (LLM_function.py ëŒ€ì²´)
def fake_process_for_commands(text, additional_prompt=""):
	"""LLM_function.pyì˜ process_voice_text ëŒ€ì²´ í•¨ìˆ˜"""
	print("\nğŸ­ [FAKE] ì‹¤ì œ LLM ëŒ€ì‹  ë¯¸ë¦¬ ì •ì˜ëœ ëª…ë ¹ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
	selected_commands = CURRENT_SELECTIONS["commands"]
	return PREDEFINED_RESPONSES["commands"][selected_commands]

# ê°€ì§œ process_for_conversation í•¨ìˆ˜ (LLM_conversation.py ëŒ€ì²´)
def fake_process_for_conversation(text, additional_prompt=""):
	"""LLM_conversation.pyì˜ process_voice_text ëŒ€ì²´ í•¨ìˆ˜"""
	print("\nğŸ­ [FAKE] ì‹¤ì œ LLM ëŒ€ì‹  ë¯¸ë¦¬ ì •ì˜ëœ ëŒ€í™” ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
	selected_conversation = CURRENT_SELECTIONS["conversation"]
	return PREDEFINED_RESPONSES["conversation"][selected_conversation]

manager = MultiThreadManager()

# Audio recording settings - Optimized for Raspberry Pi
SAMPLE_RATE = 8000     # Reduced from 16000 for faster upload (still decent quality)
CHANNELS = 1           # Mono
VOICE_ID = "ErXwobaYiN019PkySvjV"    # Voice ID for ElevenLabs - antoni (ë‚¨ì„±, ë¯¸êµ­ ì–µì–‘)
WAIT_AUDIO_FILE = "wait.mp3"  # Fixed wait message file
RESPONSE_AUDIO_FILE = "response.mp3"  # Response audio file (generated by text_to_audio.py)
OUTPUT_AUDIO_FILE = "out.mp3"
# ì†Œë¦¬ ê°ì§€ ì„¤ì • - Raspberry Pi optimized
THRESHOLD_DB = -35     # ë…¹ìŒ ì‹œì‘ì„ ìœ„í•œ ì„ê³„ ë°ì‹œë²¨ (ì ì ˆí•œ ê°’ìœ¼ë¡œ ì¡°ì • í•„ìš”)
SILENCE_THRESHOLD_DB = -35  # ë…¹ìŒ ì¢…ë£Œë¥¼ ìœ„í•œ ì„ê³„ ë°ì‹œë²¨ (ì ì ˆí•œ ê°’ìœ¼ë¡œ ì¡°ì • í•„ìš”)
SILENCE_DURATION = 2.0  # ë…¹ìŒ ì¢…ë£Œë¥¼ ìœ„í•œ ì¹¨ë¬µ ì§€ì† ì‹œê°„(ì´ˆ) - ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ 1ì´ˆë¡œ ë‹¨ì¶•

frames = []
recording = False
recording_start_time = None  # ë…¹ìŒ ì‹œì‘ ì‹œê°„ ì¶”ì  - ì¶”ê°€
silence_start_time = None
last_db_print_time = 0  # ë°ì‹œë²¨ ì¶œë ¥ ì œí•œì„ ìœ„í•œ ë§ˆì§€ë§‰ ì¶œë ¥ ì‹œê°„
last_countdown_time = 0  # ì¹´ìš´íŠ¸ë‹¤ìš´ ì¶œë ¥ ì œí•œì„ ìœ„í•œ ë§ˆì§€ë§‰ ì¶œë ¥ ì‹œê°„
DB_PRINT_INTERVAL = 0.5  # ë°ì‹œë²¨ ì¶œë ¥ ê°„ê²©(ì´ˆ)
COUNTDOWN_PRINT_INTERVAL = 0.2  # ì¹´ìš´íŠ¸ë‹¤ìš´ ì¶œë ¥ ê°„ê²©(ì´ˆ)
recording_completed = False  # ë…¹ìŒ ì™„ë£Œ í”Œë˜ê·¸ (ë…¹ìŒë§Œ ì¤‘ë‹¨í•˜ê³  ì´í›„ ì²˜ë¦¬ëŠ” ê³„ì†í•¨)
processing_audio = False

def calculate_db(audio_data):
	"""ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ ë°ì‹œë²¨ ë ˆë²¨ ê³„ì‚°"""
	if len(audio_data) == 0:
		return -np.inf
	# RMS ê°’ ê³„ì‚°
	rms = np.sqrt(np.mean(np.square(audio_data)))
	# RMSë¥¼ dBë¡œ ë³€í™˜ (0 dB ê¸°ì¤€ì€ ìµœëŒ€ ê°€ëŠ¥ ì§„í­ 1.0)
	if rms > 0:
		db = 20 * np.log10(rms)
	else:
		db = -np.inf
	return db

record_count = 0

def audio_callback(indata, frames_count, time_info, status):
	"""Callback function for audio stream"""
	global frames, recording, recording_start_time, silence_start_time, last_db_print_time, last_countdown_time, recording_completed, record_count, manager, api_lock, processing_audio
	if status:
		print(f"âš ï¸ Recording warning: {status}")
	
	# ì´ë¯¸ ë…¹ìŒì´ ì™„ë£Œë˜ì—ˆìœ¼ë©´ ë°ì´í„° ìˆ˜ì§‘í•˜ì§€ ì•ŠìŒ
	if recording_completed:
		return
	
	# í˜„ì¬ ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ ë°ì‹œë²¨ ë ˆë²¨ ê³„ì‚°
	current_db = calculate_db(indata)
	
	# í˜„ì¬ ì‹œê°„
	current_time = time.time()
	
	# ì¼ì • ê°„ê²©ìœ¼ë¡œ í˜„ì¬ ë°ì‹œë²¨ ì¶œë ¥
	if current_time - last_db_print_time >= DB_PRINT_INTERVAL:
		db_status = ""
		if current_db > THRESHOLD_DB:
			db_status = "ğŸ”Š ACTIVE"
		elif current_db < SILENCE_THRESHOLD_DB:
			db_status = "ğŸ”ˆ SILENT"
		else:
			db_status = "ğŸ”‰ NORMAL"
		
		print(f"ğŸ¤ Sound level: {current_db:.1f} dB {db_status}")
		last_db_print_time = current_time
	
	# ë…¹ìŒ ì¤‘ì´ ì•„ë‹ ë•Œ, ì„ê³„ê°’ ì´ìƒì´ë©´ ë…¹ìŒ ì‹œì‘
	if not recording and current_db > THRESHOLD_DB:
		recording = True
		frames.clear()
		silence_start_time = None
		recording_start_time = current_time
		record_count=0
		print(f"\nâºï¸ Recording started automatically (detected {current_db:.2f} dB > threshold {THRESHOLD_DB} dB)...")

		manager.start_vlm_processing()  # VLM ì²˜ë¦¬ í™œì„±í™”
		
	# ë…¹ìŒ ì¤‘ì¼ ë•Œ
	if recording:
		frames.append(indata.copy())
		record_count+=1
		
		# ì„ê³„ê°’ ì´í•˜ì˜ ì†Œë¦¬ê°€ ê°ì§€ë˜ë©´ ì¹¨ë¬µ ì‹œê°„ ì²´í¬ ì‹œì‘/ì—…ë°ì´íŠ¸
		if current_db < SILENCE_THRESHOLD_DB:
			if silence_start_time is None:
				silence_start_time = current_time
				print(f"\nâ¸ï¸ Silence detected ({current_db:.2f} dB < threshold {SILENCE_THRESHOLD_DB} dB)")
			
			# ì¹¨ë¬µ ê²½ê³¼ ì‹œê°„
			elapsed_silence = current_time - silence_start_time
			# ì¢…ë£Œê¹Œì§€ ë‚¨ì€ ì‹œê°„
			remaining_time = SILENCE_DURATION - elapsed_silence
			
			# ì¼ì • ê°„ê²©ìœ¼ë¡œ ì¹´ìš´íŠ¸ë‹¤ìš´ ì¶œë ¥
			if current_time - last_countdown_time >= COUNTDOWN_PRINT_INTERVAL and remaining_time > 0:
				print(f"â±ï¸ Recording will end in: {remaining_time:.1f} seconds...")
				last_countdown_time = current_time
			
			# ì¹¨ë¬µ ì‹œê°„ì´ ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ ë…¹ìŒ ì¢…ë£Œ
			if elapsed_silence >= SILENCE_DURATION:
				recording = False
				recording_completed = True  # ë…¹ìŒ ì™„ë£Œ í”Œë˜ê·¸ ì„¤ì • (ë” ì´ìƒ ì˜¤ë””ì˜¤ ì…ë ¥ì„ ë°›ì§€ ì•ŠìŒ)
				processing_audio = True
				print(f"\nâ¹ï¸ Recording ended automatically (silence for {SILENCE_DURATION} seconds).")
				processing_thread = threading.Thread(
					target=process_recorded_audio_async,
					daemon=True
				)
				processing_thread.start()
		else:
			# ì†Œë¦¬ê°€ ë‹¤ì‹œ ì„ê³„ê°’ ì´ìƒì´ ë˜ë©´ ì¹¨ë¬µ íƒ€ì´ë¨¸ ì´ˆê¸°í™”
			if silence_start_time is not None:
				print(f"ğŸ”Š Voice detected again ({current_db:.2f} dB > {SILENCE_THRESHOLD_DB} dB) - Silence timer reset")
				silence_start_time = None

def process_recorded_audio_async():
	"""ë¹„ë™ê¸°ë¡œ ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì²˜ë¦¬"""
	global processing_audio, recording_completed
	
	try:
		process_recorded_audio()
	finally:
		# ì²˜ë¦¬ ì™„ë£Œ í›„ í”Œë˜ê·¸ ë¦¬ì…‹
		processing_audio = False
		recording_completed = False
		print("\nğŸ¤ Ready for next recording...")

def process_recorded_audio():
	"""ë…¹ìŒëœ ì˜¤ë””ì˜¤ ì²˜ë¦¬"""
	global frames
	
	if not frames:  # Skip if no audio was recorded
		print("No audio recorded. Try again.")
		return
	
	print("\nğŸ”„ Processing recorded audio...")
	print("ğŸ”Š Playing wait message...")
	try:
		import pygame
		pygame.mixer.init()
		pygame.mixer.music.load(WAIT_AUDIO_FILE)
		pygame.mixer.music.play()
		while pygame.mixer.music.get_busy():
			pygame.time.Clock().tick(10)
	except ImportError:
		print(f"âš ï¸ pygame not installed. Cannot play {WAIT_AUDIO_FILE}")
		
	print("\nâ³ Waiting for VLM (Vision Language Model) result...")
	manager.start_vlm_processing()  # VLM ì²˜ë¦¬ í™œì„±í™”
	vlm_result = manager.get_vlm_result(timeout=40)
	if vlm_result:
		print(f"ğŸ¯ VLM analysis complete: {vlm_result[:100]}..." if len(vlm_result) > 100 else f"ğŸ¯ VLM analysis complete: {vlm_result}")
	else:
		print("âš ï¸ VLM processing timeout or failed")
	
	# Convert audio data to numpy array
	print("\nğŸ“Š Preparing audio data for transcription...")
	audio_data = np.concatenate(frames, axis=0)

	# 1. Convert audio to text using Whisper API (ê°€ì§œ í•¨ìˆ˜ë¡œ ëŒ€ì²´)
	print("\nğŸ™ï¸ Converting speech to text (ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ëŒ€ì²´ë¨)...")
	transcribed_text = fake_convert_audio_to_text_via_api(audio_data, SAMPLE_RATE)

	if transcribed_text and not transcribed_text.startswith("/set"):
		print(f"âœ… ì…ë ¥ëœ í…ìŠ¤íŠ¸: \"{transcribed_text}\"")

		# 2. Start conversation processing using the transcribed text (threaded)
		print("\nğŸ¤– Generating VIRUS conversational response (async thread)...")
		manager.start_text_conversation_processing(transcribed_text, vlm_result)

		# 3. Process command interpretation using the transcribed text
		print("âš™ï¸ Interpreting robot commands...")
		command_response_json = None
		try:
			# ì‹¤ì œ process_for_commands ëŒ€ì‹  ê°€ì§œ í•¨ìˆ˜ ì‚¬ìš©
			command_response_json = fake_process_for_commands(
				transcribed_text,
				additional_prompt=f"[Image/Video Description]: {vlm_result}"
			)
			print(f"â†’ Robot command generated: {command_response_json}")
		except Exception as e:
			print(f"âŒ Command processing error: {e}")
			command_response_json = None
	else:
		if not transcribed_text:
			print("âš ï¸ No transcribed text available for command processing")
		else:
			print("âš ï¸ ì„¤ì • ëª…ë ¹ì´ ì…ë ¥ë˜ì—ˆìŠµë‹ˆë‹¤. ëª…ë ¹ ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
		
	if command_response_json and not transcribed_text.startswith("/set"):
		print(f"\nğŸ¤– Executing robot command sequence...")
		try:
			run_spike(command_response_json)
			print("âœ… Robot command executed successfully")
		except Exception as e:
			print(f"âŒ Robot command execution error: {e}")
	else:
		print("â„¹ï¸ No robot command to execute")
		
	print("\nâ³ Waiting for conversational response to complete...")
	conversation_completed = manager.get_conversation_result(timeout = 40)
	if conversation_completed:
		print("âœ… Conversational response completed")
	else:
		print("âš ï¸ Conversational response timeout or failed")
		
	print("\nâœ… All processing completed. Ready for next command...")
	frames.clear()

def process_complete_interaction():
	"""Main function to handle the complete interaction flow"""
	global processing_audio, recording_completed, recording
	processing_audio = False
	recording_completed = False
	recording = False
	
	# ìë™ ë…¹ìŒ ëŒ€ì‹  ì‚¬ìš©ì ì…ë ¥ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
	print("\nğŸ­ [FAKE] ì‹¤ì œ ìŒì„± ì…ë ¥ ëŒ€ì‹  í‚¤ë³´ë“œ ì…ë ¥ì„ ë°›ìŠµë‹ˆë‹¤.")
	print("í˜„ì¬ ëª¨ë“  ì¹´í…Œê³ ë¦¬ëŠ” 'default' ì‘ë‹µì„ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
	print("ëª…ë ¹ì„ ì…ë ¥í•˜ë ¤ë©´ Enter í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
	
	while True:
		try:
			choice = input("\nğŸ¤ Enter í‚¤ë¥¼ ëˆŒëŸ¬ ê¸°ë³¸ ëª…ë ¹ ì‹¤í–‰ ë˜ëŠ” '/set'ìœ¼ë¡œ ì‘ë‹µ ë³€ê²½ (ì¢…ë£Œ: Ctrl+C): ")
			
			# '/set' ëª…ë ¹ì–´ê°€ ì•„ë‹ ê²½ìš° ë°”ë¡œ default ì‘ë‹µ ì‹¤í–‰
			if not choice.startswith('/set'):
				frames.clear()  # í”„ë ˆì„ ì´ˆê¸°í™”
				frames.append(np.zeros((1000, 1), dtype=np.float32))  # ë”ë¯¸ ì˜¤ë””ì˜¤ ë°ì´í„°
				
				# '/set' ëª…ë ¹ì–´ ì—†ì´ ë°”ë¡œ default ì‘ë‹µ ì‚¬ìš©
				if choice.strip() == '':
					print("\nâœ… ê¸°ë³¸(default) ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
					process_recorded_audio()
				else:
					# ì‚¬ìš©ìê°€ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•œ ê²½ìš° í•´ë‹¹ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
					frames.clear()
					frames.append(np.zeros((1000, 1), dtype=np.float32))
					process_recorded_audio()
			else:
				# '/set' ëª…ë ¹ì–´ ì²˜ë¦¬ ìœ ì§€
				try:
					_, category, selection = choice.split(" ", 2)
					if category in CURRENT_SELECTIONS and selection in PREDEFINED_RESPONSES[category]:
						CURRENT_SELECTIONS[category] = selection
						print(f"âœ… {category} ì‘ë‹µì´ '{selection}'ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
					else:
						print(f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ ë˜ëŠ” ì„ íƒ: {category} - {selection}")
						print(f"ìœ íš¨í•œ ì˜µì…˜: {list(PREDEFINED_RESPONSES.keys())} - {PREDEFINED_RESPONSES[category].keys() if category in PREDEFINED_RESPONSES else 'ì—†ìŒ'}")
				except ValueError:
					print("âŒ ëª…ë ¹ í˜•ì‹ ì˜¤ë¥˜. ì˜ˆ: /set commands attack")
					print_help()
		except KeyboardInterrupt:
			print("\nğŸ”Œ Shutting down system.")
			break

def print_help():
	"""ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´ì™€ ì„¤ì • ì˜µì…˜ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
	print("\n" + "=" * 50)
	print("ğŸ”§ ê°€ì§œ VIRUS ì‹œìŠ¤í…œ ëª…ë ¹ì–´")
	print("=" * 50)
	print("ì¼ë°˜ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ëª…ë ¹ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
	print("\níŠ¹ìˆ˜ ëª…ë ¹ì–´:")
	print("  /set [category] [selection] - ì‘ë‹µ ìœ í˜• ì„¤ì •")
	print("  ì˜ˆ: /set commands attack")
	
	print("\nì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ ë° ì„ íƒ ì˜µì…˜:")
	for category, options in PREDEFINED_RESPONSES.items():
		print(f"  {category}: {', '.join(options.keys())}")
	
	print("\ní˜„ì¬ ì„¤ì •:")
	for category, selection in CURRENT_SELECTIONS.items():
		print(f"  {category}: {selection}")
	print("=" * 50)

def run_spike(llmcmd='[[ { "cmd": "shoot",    "val":  0 }]]'):
	# 1) í—ˆë¸Œ ì»¨íŠ¸ë¡¤ëŸ¬ ë‘ ê°œ ìƒì„±
	

	# 3) ì—°ê²° í™•ì¸
	if not hub1.sock or not hub2.sock:
		print("ì—°ê²° ì‹¤íŒ¨! í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
		return

	# 4) ì‚¬ìš©ì ì…ë ¥ ë˜ëŠ” ì¸ìë¡œ ë°›ì€ llmcmd ì‚¬ìš©
	if llmcmd:
		cmd_input = llmcmd.strip()
	else:
		cmd_input = input("ëª…ë ¹ ì…ë ¥ (ì—”í„° ì‹œ ìƒ˜í”Œ ëª…ë ¹ ì‚¬ìš©): ").strip()
		if not cmd_input:
			# ì—”í„°ë§Œ ì³¤ì„ ë•Œ, ë‘ í—ˆë¸Œìš© ìƒ˜í”Œ ëª…ë ¹ì„ ë¬¶ì–´ì„œ ë³´ë‚¸ë‹¤ëŠ” ê°€ì •
			# (ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ ë…¼ë¦¬ì— ë§ê²Œ ìˆ˜ì • ê°€ëŠ¥)
			# ì˜ˆë¥¼ ë“¤ì–´, ìƒ˜í”Œì„ "hub1â†’hub2"ë¡œ ë™ì¼í•˜ê²Œ ë³´ë‚´ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´:
			cmd_input = SAMPLE_COMMANDS["hub1"]

	# 5) JSON íŒŒì‹±
	try:
		# cmd_inputì€ ì˜ˆ: '[ [ {...} ], [ {...} ] ]' í˜•íƒœì—¬ì•¼ í•¨
		# ìµœìƒìœ„ ê°ì²´ê°€ ë¦¬ìŠ¤íŠ¸(list)ì´ì–´ì•¼ forë¬¸ì´ ì •ìƒ ë™ì‘
		parsed_cmd_list = json.loads(cmd_input)
		if not isinstance(parsed_cmd_list, list):
			raise ValueError("ìµœìƒìœ„ JSON ê°ì²´ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤.")
	except Exception as e:
		print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
		return

	# 6) ëª…ë ¹ ìˆœì°¨ ì²˜ë¦¬
	try:
		for single_cmd in parsed_cmd_list:
			# single_cmdëŠ” ì´ì œ Python ë¦¬ìŠ¤íŠ¸ ìë£Œêµ¬ì¡°: [ { "cmd": "...", "val": ... }, ... ]
			if not isinstance(single_cmd, list):
				print(f"ì˜ëª»ëœ ëª…ë ¹ í˜•ì‹: {single_cmd} (ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜)")
				continue

			# 6-1) ì´ ëª…ë ¹ ë¸”ë¡ì— "shoot, val=0" ì¡°ê±´ì´ ìˆëŠ”ì§€ ê²€ì‚¬
			is_shoot_zero = False
			for cmd_dict in single_cmd:
				cmd_name = cmd_dict.get("cmd")
				cmd_val  = cmd_dict.get("val")

				# JSONì—ì„œ valì´ ë¬¸ìì—´ë¡œ ì™”ì„ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ int ë³€í™˜ ì‹œë„
				try:
					val_int = int(cmd_val)
				except:
					val_int = None

				if cmd_name == "shoot" and val_int == 0:
					is_shoot_zero = True
					break

			# 6-2) "shoot val=0" ì´ë©´ face ì²˜ë¦¬ ì‹œì‘
			if is_shoot_zero:
				face_mgr.start_face_processing()
				result = face_mgr.get_face_result(timeout=10)
				if result is None:
					print("[face] ê²°ê³¼ë¥¼ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ shoot ì»¤ë§¨ë“œë§Œ ì „ì†¡í•©ë‹ˆë‹¤.")
					# ì˜ˆ: ì•„ë¬´ ëŒ€ìƒ ì§€ì • ì—†ì´ í—ˆë¸Œì— shoot=1 ì „ì†¡
					fallback_json = json.dumps([{"cmd": "shoot", "val": 1}])
					t1 = threading.Thread(target=hub1.send_single_command, args=(fallback_json,))
					t2 = threading.Thread(target=hub2.send_single_command, args=(fallback_json,))
					t1.start(); t2.start()
					t1.join(timeout = 15); t2.join(timeout = 15)
				else:
					# face_resultê°€ JSON ë¬¸ìì—´ì´ë¼ê³  ê°€ì •
					"""try:
						face_list = json.loads(result)
						# face_listëŠ” [ { "label": "...", "center": [x, y] }, ... ] í˜•íƒœ
					except Exception as e:
						print(f"[face] result JSON íŒŒì‹± ì˜¤ë¥˜: {e}\n raw result: {result}")
						face_list = []"""

					# ì˜ˆ: "label == 'enemy'" ì¸ ê²ƒë§Œ ì²˜ë¦¬
					for detect in result:
						r = detect.get("label") 
						if r == "enemy" or r == "Jeoung":
							center = detect.get("center", [0, 0])
							x, y = center[0], center[1]

							# í”½ì…€ ì¢Œí‘œë¥¼ ê°ë„ë¡œ ë³€í™˜
							# í™”ë©´ ì¤‘ì•™ì„ (320, 240)ìœ¼ë¡œ ë³´ê³ , ìƒëŒ€ ì¢Œí‘œ ê³„ì‚°
							rel_x = 320 - x  # ì¤‘ì•™ìœ¼ë¡œë¶€í„°ì˜ x ê±°ë¦¬
							rel_y = 240 - y  # ì¤‘ì•™ìœ¼ë¡œë¶€í„°ì˜ y ê±°ë¦¬
							
							# í™”ê°ì„ ê¸°ì¤€ìœ¼ë¡œ ê°ë„ ê³„ì‚° (ì˜ˆ: ìˆ˜í‰ 60ë„, ìˆ˜ì§ 45ë„ ì‹œì•¼ê° ê°€ì •)
							# 1í”½ì…€ë‹¹ ê°ë„ = ì‹œì•¼ê° / í•´ìƒë„
							angle_x = (rel_x * 60) / 1000  # ìˆ˜í‰ê°: Â±30ë„
							angle_y = (rel_y * 45) / 500  # ìˆ˜ì§ê°: Â±22.5ë„

							# íšŒì „ ëª…ë ¹ ì „ì†¡ (í•œë²ˆë§Œ íšŒì „)
							rotation_cmd = json.dumps([
								{"cmd": "rotate_x", "val": angle_x},
								{"cmd": "rotate_y", "val": angle_y}
							])
							shoot_cmd = json.dumps([{"cmd": "shoot", "val": 1}])
							return_cmd = json.dumps([
								{"cmd": "rotate_x", "val": -angle_x},
								{"cmd": "rotate_y", "val": -angle_y}
							])

							# 1. íƒ€ê²Ÿ ë°©í–¥ìœ¼ë¡œ íšŒì „
							t1 = threading.Thread(target=hub1.send_single_command, args=(rotation_cmd,))
							t2 = threading.Thread(target=hub2.send_single_command, args=(rotation_cmd,))
							t1.start(); t2.start()
							t1.join(timeout = 15); t2.join(timeout = 15)

							# 2. ë°œì‚¬
							t1 = threading.Thread(target=hub1.send_single_command, args=(shoot_cmd,))
							t2 = threading.Thread(target=hub2.send_single_command, args=(shoot_cmd,))
							t1.start(); t2.start()
							t1.join(timeout = 15); t2.join(timeout = 15)

							# 3. ì›ìœ„ì¹˜ë¡œ ë³µê·€
							time.sleep(0.5)  # ë°œì‚¬ ë™ì‘ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
							t1 = threading.Thread(target=hub1.send_single_command, args=(return_cmd,))
							t2 = threading.Thread(target=hub2.send_single_command, args=(return_cmd,))
							t1.start(); t2.start()
							t1.join(timeout = 15); t2.join(timeout = 15)
							
							# ì²« ë²ˆì§¸ enemyë§Œ ì²˜ë¦¬í•˜ê³  ì¢…ë£Œ
							break
					# ë§Œì•½ ì (enemy)ì´ í•œ ëª…ë„ ì•ˆ ì¡í˜”ìœ¼ë©´, ê¸°ë³¸ shootë§Œ ë³´ë‚´ë„ ë¨
					# if not any(d.get("label") == "enemy" for d in result):
					#     fallback_json = json.dumps([{"cmd": "shoot", "val": 1}])
					#     t1 = threading.Thread(target=hub1.send_single_command, args=(fallback_json,))
					#     t2 = threading.Thread(target=hub2.send_single_command, args=(fallback_json,))
					#     t1.start(); t2.start()
					#     t1.join(); t2.join()

			# 6-3) "shoot val=0"ì´ ì•„ë‹ˆë©´, ë‹¨ìˆœíˆ ì´ ëª…ë ¹ ë¸”ë¡ ìì²´ë¥¼ í—ˆë¸Œë“¤ë¡œ ì „ì†¡
			else:
				# single_cmdëŠ” Python ë¦¬ìŠ¤íŠ¸ ê°ì²´ì´ë¯€ë¡œ, ë°˜ë“œì‹œ JSON ë¬¸ìì—´ë¡œ ì§ë ¬í™”
				json_payload = json.dumps(single_cmd)
				t1 = threading.Thread(target=hub1.send_single_command, args=(json_payload,))
				t2 = threading.Thread(target=hub2.send_single_command, args=(json_payload,))
				t1.start(); t2.start()
				t1.join(timeout = 15); t2.join(timeout = 15)
	except KeyboardInterrupt:
		print("\ní”„ë¡œê·¸ë¨ ê°•ì œ ì¢…ë£Œ.")

if __name__ == "__main__":
	# Display welcome message
	print("=" * 50)
	print("ê°€ì§œ VIRUS COMBAT ROBOT CONTROL SYSTEM")
	print("Versatile, Intelligent Robotic Unit for Strategy")
	print("=" * 50)
	print("ì´ ì‹œìŠ¤í…œì€ ì‹¤ì œ LLM/VLM ëŒ€ì‹  ì‚¬ìš©ìê°€ ë¯¸ë¦¬ ì •ì˜í•œ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
	print("ì—”í„°í‚¤ë§Œ ëˆ„ë¥´ë©´ ë°”ë¡œ ê¸°ë³¸(default) ì‘ë‹µì´ ì‹¤í–‰ë©ë‹ˆë‹¤.")
	print("ì‘ë‹µì„ ë³€ê²½í•˜ê³  ì‹¶ìœ¼ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì„¸ìš”: /set [category] [selection]")
	print("ì˜ˆ: /set commands attack")
	print("   /set conversation hello")
	print("   /set vlm person")
	print("\ní˜„ì¬ ì„¤ì •ëœ ì‘ë‹µ:")
	for category, selection in CURRENT_SELECTIONS.items():
		print(f"  - {category}: {selection}")
	print("\nì‚¬ìš© ê°€ëŠ¥í•œ ì„ íƒì§€ ëª©ë¡ì„ ë³´ë ¤ë©´ ë‹¤ìŒì„ ì…ë ¥í•˜ì„¸ìš”: /help")
	print("=" * 50)
	
	# Start the interaction loop
	process_complete_interaction()
